\documentclass{article}
\input{preamble.tex}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.17}
    % \pgfplotsset{
    %     compat=1.9,
    %     compat/bar nodes=1.8,
    % }



\title{INF236 - Assignment 1}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
    
    \section*{Problem 1}
    \addcontentsline{toc}{section}{Problem 1}

    The implementation of sequential radix sort has been implemented in the following manner.

\begin{algorithm}[H]
    \caption{Sequential Radix Sort}
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetAlgoVlined
    \SetKwFor{For}{for}{do}{}
    \SetKw{KwTo}{to}
    \SetKw{KwBy}{by}
    
    \Input{\(n\) - The length of the array, \(b\) - Key size (how many bits to interpret as one digit)}
    \Output{\(t\) - the time taken to sort the array}
    \(a \leftarrow\) array of random unsigned 64-bit integers of size \(n\)

    \(tmp \leftarrow\) partially sorted array of size \(n\), initialized with 0

    \(buckets \gets 2^{b}\)
    
    \For{\(shift \gets 0\) \KwTo \(64\) \KwBy \(b\)}{
        \(bucketSize \leftarrow\) array of size \(buckets\), initialized with 0
        
        \For{\(i \gets 0\) \KwTo \(n - 1\)}{
            \(bucket \gets (a[i] \gg shift) \& (buckets - 1)\)

            \(bucketSize[bucket]\)++
        }
        
        % verify this is correct
        \(sum \gets 0\)\;

        \( bucketSize[0] \gets 0 \)

        \For{\(i \gets 1\) \KwTo \(buckets - 1\)}{
            % \(sum \gets sum + bucketSize[i]\)
            \( t \gets sum  + bs[i] \)

            \(bucketSize[i] \gets t\)

            \( sum \gets t \)
        }
        
        \For{\(i \gets 0\) \KwTo \(n-1\)}{
            \(bucket \gets (a[i] \gg shift) \& (buckets - 1)\)

            \(tmp[bucketSize[bucket]\)\(] \gets a[i]\)

            \( bucketSize[bucket] \)++
        }
        

        % for (int i = 0; i < n; i++) {
        %     ull val = a[i];                         // get value
        %     int t = (val >> shift) & (buckets - 1); // get bucket
        %     permuted[bs[t]++] = val;
        % }
        \(a \gets tmp\)\;
    }
\end{algorithm}

Firstly, we allocate memory for \( a \) and \( tmp \). \( a \) represents the input array, and will also contain the final sorted array, whereas \( tmp \) will store the partially sorted array during execution. \( a \) will be swapped with \( tmp \) every time the outermost for loop is done executing one iteration.
\medskip

The outermost for loop iterates from 0 to 64, with a step size of \( b \), where \( b \) represents how many bits should be interpreted as one digit. It iterates up to 64 bits, as this is the size of an \texttt{unsigned long long} type in \texttt{c}.
\medskip

Each time this for loop iterates, it goes through 3 stages.

\paragraph{Stage 1 - Counting how many elements for each bucket}
In this stage, we iterate through the array containing our values. For each element \( x \) stored in \( a[i] \), we want to figure out in which bucket this element should be placed into. Given \( s \), representing the power we should raise \( x \) to, and \( k \), representing how many buckets there are, we can obtain \( b \), representing the bucket \( x \) belongs in. This can be done with the following formula

\[ b = \left\lfloor\frac{x}{2^{s}}\right\rfloor \wedge k-1 \]

Which can be implemented in \texttt{c} as \(bucket \leftarrow (a[i] \gg shift) \& (buckets - 1)\).

\paragraph{Stage 2 - Prefix sum}
In this stage, we need to perform a prefix sum operation on the \( bucketSize \) array. This is done in order to ensure we start placing the elements in the buckets at the correct index in the \( tmp \) array in the next stage.

\paragraph{Stage 3 - Creating the partially sorted array}
In this stage, we need to place our elements at the correct index in the \( tmp \) array. This is done by again, computing which bucket element \( a[i] \) belongs to. After we have found the bucket, we place this element in the \( tmp \) array, at index \( bucketSize[bucket] \). Because we performed the prefix sum over the \( bucketSize \) array in the previous stage, this variable contains the index at which the elements belonging to this bucket should be placed in the \( tmp \) array. After we have placed element \( a[i] \), we increment this index pointer, such that we avoid overwriting anything.


\section*{Problem 2}
\addcontentsline{toc}{section}{Problem 2}

Through trial and error, the maximum elements that could be sorted in 10 seconds, was 60 million, with a value of \( b = 4 \). Varying \( b \) by powers of 2, we obtain the following execution times for sorting 60 million elements


\pgfplotstableread{
Label Count Prefix Sort
1 12.115614 0.000003 20.418564
2 6.105506 0.000002 10.341313
4 3.032052 0.000001 6.576575
8 1.765580 0.000003 12.249412
16 1.951417 0.000356 16.018882
}\testdata

\begin{figure}[H]
    \begin{center}
\begin{tikzpicture}
\begin{axis}[
    ybar stacked,
    ymin=0,
    ymax=35,
    ylabel={Time [s]},
    xtick=data,
    xticklabels from table={\testdata}{Label},
    xticklabel style={text width=2cm,align=center},
    xlabel={\( b \)-value},
    legend pos=outer north east,
    legend style={cells={anchor=west},fill=GBBackground,draw=GBForeground, legend pos=outer north east},
    % reverse legend=true, % set to false to get correct display, but I'd like to have this true
    bar width=20pt,
]
% Add the data, ensuring the x values are in the log scale (if necessary)
\addplot [fill=GBGreen] table [y=Count, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Count}
\addplot [fill=GBRed!60] table [y=Prefix, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Prefix}
\addplot [fill=GBBlue, point meta=y] table [y=Sort, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Sort}

\addplot [
ybar, % this makes it show the total for some reason
nodes near coords,
nodes near coords style={%
    anchor=south,%
},
] table [ y expr=0.00001, x expr=\coordindex] {\testdata};
\end{axis}
\end{tikzpicture}
    \end{center}
    \caption{Sorting 60 million elements with varying \( b \) values. \textbf{NOTE:} Prefix value is so low its not visible.}
\end{figure}

As we can see, using a value \( b \) value of \( 4 \), yields the best running time. When we use \( b = 4 \), we have the option to place elements into \( 2^{4} = 16  \) different buckets. We also only have to perform the 3 stages described earlier \( \frac{64}{4} = 16 \) times.
\medskip


Both the \textit{Counting} and \textit{Sorting} stage have a time complexity of \( \mathcal{O}\left(n\right) \), and the \textit{Prefix Sum} stage only has a time complexity of \( \mathcal{O}\left(k\right) \), with \( k \) being the number of buckets. Because \( k \ll n \) when \( n \) is sufficiently large, we don't see the impact of this stage in the plot, as it happens almost instantly.
\medskip

But what explains the difference in execution time for the \textit{Counting} and \textit{Sorting} stage? To figure out why, we need to take a look at their implementation.

\begin{figure}[h]
    \centering

    \begin{minipage}{0.47\textwidth}
        \begin{lstlisting}
for (int i = 0; i < n; i++) {
    ull val = a[i];
    int t = (val >> shift) & (buckets - 1);
    bucketSize[t]++;
}
        \end{lstlisting}
        \caption{Counting stage}
    \end{minipage}\hfill
    \begin{minipage}{0.47\textwidth}
        \begin{lstlisting}
for (int i = 0; i < n; i++) {
    ull val = a[i];                         
    int t = (val >> shift) & (buckets - 1);
    permuted[bs[t]++] = val;
}
        \end{lstlisting}
        \caption{Sorting stage}
    \end{minipage}
    \end{figure}

    As we can see, the implementation of the two stages are similar, but with some key differences. In the coutning stage, we fill the \textit{bucketSize} to count how many elements are in each bucket. This array is of size \( 2^{b} \), and is at most of size \( 2^{16} = 65536 \). If we run the command \texttt{lscpu}, we cann see that the \texttt{L1d cachce} size is 32K, which means that the L1 cache can store up to 32KB, which is equivalent to 8192 integers, given that an integer is 4 bytes. This means that for all values of \( b < 16\), the entire bucket array fits into this cache, allowing us to read and write to this array very fast. The size of the bucket array is also always a power of 2, which means that it will line up nicely within cache lines, which minimizes cache misses.
\medskip

In the sorting stage however, we are writing to the \textit{permuted} array, which is of size \( n \). This means that for large values of \( n \), this array does not fit nicely into L1 or even L2 cache (which can store up to 256KB), which results in slower memory access to this array. In addition, there is no ordering of which buckets are accessed when, which means that the array is written to in a random and sporadic pattern, which yields poor memory access patterns, further slowing us down.


\end{document}
