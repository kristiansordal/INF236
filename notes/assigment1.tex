\documentclass{article}
\input{preamble.tex}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.17}
    % \pgfplotsset{
    %     compat=1.9,
    %     compat/bar nodes=1.8,
    % }



\title{INF236 - Assignment 1}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
    
    \section*{Problem 1}
    \addcontentsline{toc}{section}{Problem 1}

    The implementation of sequential radix sort has been implemented in the following manner.

\begin{algorithm}[H]
    \caption{Sequential Radix Sort}
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetAlgoVlined
    \SetKwFor{For}{for}{do}{}
    \SetKw{KwTo}{to}
    \SetKw{KwBy}{by}
    
    \Input{\(n\) - The length of the array, \(b\) - Key size (how many bits to interpret as one digit)}
    \Output{\(t\) - the time taken to sort the array}
    \(a \leftarrow\) array of random unsigned 64-bit integers of size \(n\)

    \(tmp \leftarrow\) partially sorted array of size \(n\), initialized with 0

    \(buckets \gets 2^{b}\)
    
    \For{\(shift \gets 0\) \KwTo \(64\) \KwBy \(b\)}{
        \(bucketSize \leftarrow\) array of size \(buckets\), initialized with 0
        
        \For{\(i \gets 0\) \KwTo \(n - 1\)}{
            \(bucket \gets (a[i] \gg shift) \& (buckets - 1)\)

            \(bucketSize[bucket]\)++
        }
        
        % verify this is correct
        \(sum \gets 0\)\;

        \( bucketSize[0] \gets 0 \)

        \For{\(i \gets 1\) \KwTo \(buckets - 1\)}{
            % \(sum \gets sum + bucketSize[i]\)
            \( t \gets sum  + bs[i] \)

            \(bucketSize[i] \gets t\)

            \( sum \gets t \)
        }
        
        \For{\(i \gets 0\) \KwTo \(n-1\)}{
            \(bucket \gets (a[i] \gg shift) \& (buckets - 1)\)

            \(tmp[bucketSize[bucket]\)\(] \gets a[i]\)

            \( bucketSize[bucket] \)++
        }
        

        % for (int i = 0; i < n; i++) {
        %     ull val = a[i];                         // get value
        %     int t = (val >> shift) & (buckets - 1); // get bucket
        %     permuted[bs[t]++] = val;
        % }
        \(a \gets tmp\)\;
    }
\end{algorithm}

Firstly, we allocate memory for \( a \) and \( tmp \). \( a \) represents the input array, and will also contain the final sorted array, whereas \( tmp \) will store the partially sorted array during execution. \( a \) will be swapped with \( tmp \) every time the outermost for loop is done executing one iteration.
\medskip

The outermost for loop iterates from 0 to 64, with a step size of \( b \), where \( b \) represents how many bits should be interpreted as one digit. It iterates up to 64 bits, as this is the size of an \texttt{unsigned long long} type in \texttt{c}.
\medskip

Each time this for loop iterates, it goes through 3 stages.

\paragraph{Stage 1 - Counting how many elements for each bucket}
In this stage, we iterate through the array containing our values. For each element \( x \) stored in \( a[i] \), we want to figure out in which bucket this element should be placed into. Given \( s \), representing the power we should raise \( x \) to, and \( k \), representing how many buckets there are, we can obtain \( b \), representing the bucket \( x \) belongs in. This can be done with the following formula

\[ b = \left\lfloor\frac{x}{2^{s}}\right\rfloor \wedge k-1 \]

Which can be implemented in \texttt{c} as \(bucket \leftarrow (a[i] \gg shift) \& (buckets - 1)\).

\paragraph{Stage 2 - Prefix sum}
In this stage, we need to perform a prefix sum operation on the \( bucketSize \) array. This is done in order to ensure we start placing the elements in the buckets at the correct index in the \( tmp \) array in the next stage.

\paragraph{Stage 3 - Creating the partially sorted array}
In this stage, we need to place our elements at the correct index in the \( tmp \) array. This is done by again, computing which bucket element \( a[i] \) belongs to. After we have found the bucket, we place this element in the \( tmp \) array, at index \( bucketSize[bucket] \). Because we performed the prefix sum over the \( bucketSize \) array in the previous stage, this variable contains the index at which the elements belonging to this bucket should be placed in the \( tmp \) array. After we have placed element \( a[i] \), we increment this index pointer, such that we avoid overwriting anything.


\section*{Problem 2}
\addcontentsline{toc}{section}{Problem 2}

Through trial and error, the maximum elements that could be sorted in 10 seconds, was 60 million, with a value of \( b = 4 \). Varying \( b \) by powers of 2, we obtain the following execution times for sorting 60 million elements


\pgfplotstableread{
Label Count Prefix Sort
1 12.115614 0.000003 20.418564
2 6.105506 0.000002 10.341313
4 3.032052 0.000001 6.576575
8 1.765580 0.000003 12.249412
16 1.951417 0.000356 16.018882
}\testdata

\begin{figure}[H]
    \begin{center}
\begin{tikzpicture}
\begin{axis}[
    ybar stacked,
    ymin=0,
    ymax=35,
    ylabel={Time [s]},
    xtick=data,
    xticklabels from table={\testdata}{Label},
    xticklabel style={text width=2cm,align=center},
    xlabel={\( b \)-value},
    legend pos=outer north east,
    legend style={cells={anchor=west},fill=GBBackground,draw=GBForeground, legend pos=outer north east},
    % reverse legend=true, % set to false to get correct display, but I'd like to have this true
    bar width=20pt,
]
% Add the data, ensuring the x values are in the log scale (if necessary)
\addplot [fill=GBGreen] table [y=Count, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Count}
\addplot [fill=GBRed] table [y=Prefix, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Prefix}
\addplot [fill=GBBlue, point meta=y] table [y=Sort, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Sort}

\addplot [
ybar, % this makes it show the total for some reason
nodes near coords,
nodes near coords style={%
    anchor=south,%
},
] table [ y expr=0.00001, x expr=\coordindex] {\testdata};
\end{axis}
\end{tikzpicture}
    \end{center}
    \caption{Sorting 60 million elements with varying \( b \) values. \textbf{NOTE:} Prefix value is so low its not visible.}
\end{figure}

As we can see, using a value \( b \) value of \( 4 \), yields the best running time. When we use \( b = 4 \), we have the option to place elements into \( 2^{4} = 16  \) different buckets. We also only have to perform the 3 stages described earlier \( \frac{64}{4} = 16 \) times.
\medskip


Both the \textit{Counting} and \textit{Sorting} stage have a time complexity of \( \mathcal{O}\left(n\right) \), and the \textit{Prefix Sum} stage only has a time complexity of \( \mathcal{O}\left(k\right) \), with \( k \) being the number of buckets. Because \( k \ll n \) when \( n \) is sufficiently large, we don't see the impact of this stage in the plot, as it happens almost instantly.
\medskip

But what explains the difference in execution time for the \textit{Counting} and \textit{Sorting} stage? To figure out why, we need to take a look at their implementation.

\begin{figure}[h]
    \centering

    \begin{minipage}{0.47\textwidth}
        \begin{lstlisting}
for (int i = 0; i < n; i++) {
    ull val = a[i];
    int t = (val >> shift) & (buckets - 1);
    bucketSize[t]++;
}
        \end{lstlisting}
        \caption{Counting stage}
    \end{minipage}\hfill
    \begin{minipage}{0.47\textwidth}
        \begin{lstlisting}
for (int i = 0; i < n; i++) {
    ull val = a[i];                         
    int t = (val >> shift) & (buckets - 1);
    permuted[bs[t]++] = val;
}
        \end{lstlisting}
        \caption{Sorting stage}
    \end{minipage}
    \end{figure}

    As we can see, the implementation of the two stages are similar, but with some key differences. In the coutning stage, we fill the \textit{bucketSize} to count how many elements are in each bucket. This array is of size \( 2^{b} \), and is at most of size \( 2^{16} = 65536 \). If we run the command \texttt{lscpu}, we cann see that the \texttt{L1d cachce} size is 32K, which means that the L1 cache can store up to 32KB, which is equivalent to 8192 integers, given that an integer is 4 bytes. This means that for all values of \( b < 16\), the entire bucket array fits into this cache, allowing us to read and write to this array very fast. The size of the bucket array is also always a power of 2, which means that it will line up nicely within cache lines, which minimizes cache misses.
\medskip

In the sorting stage however, we are writing to the \textit{permuted} array, which is of size \( n \). This means that for large values of \( n \), this array does not fit nicely into L1 or even L2 cache (which can store up to 256KB), which results in slower memory access to this array. In addition, there is no ordering of which buckets are accessed when, which means that the array is written to in a random and sporadic pattern, which yields poor memory access patterns, further slowing us down.
\medskip

\paragraph{Computing an expression for execution time}
In order to compute an expression for the execution time, we can start by looking at the runtime. The runtime of radix sort, expressed in big O notation is \( \mathcal{O}\left(n \cdot  k\right) \), where \( n \) is the size of the array, and \( k \) is the key size, or how many bits to interpret as one digit. Taking a closer look at the runtime, and including constants, we can see that the three stages have the following runtimes:

\begin{align*}
    \text{Counting} & : 3n \\
    \text{Prefix Sum} & : 2 \cdot 2^{k} \\
    \text{Sorting} & : 3n
\end{align*}

So the running time of the algorithm, including constants is \( \mathcal{O}\left(k \cdot \left( 6n + 2 \cdot 2^{k} \right)\right) \). This does not tell us much about how long the algorithm will take to complete. To figure this out, we need to benchmark the different stages. We are specifically interested in how long one iteration of the \textit{Counting} stage, and the \textit{Sorting} stage will take. We will disregard the time for the prefix sum, as it runs close to instantaneously for all possible values for \( b \).
\medskip

In order to benchmark these loops, our best bet is to time each execution of the two loops individually, and put this time into two arrays of size \( \frac{64}{b} \), then accumulate this time and divide it by \( b \cdot n \). Mathematically, this can be expressed as

\[ t_{avg} = \frac{t_{tot}}{n \cdot  b} \]

Where \( t_{tot} \) is the total time for \( b \) executions of the loop. By runnning the sequential program with \( n = 1 \times 10^{7} \), and \( b = 8 \), we obtained the time of execution for one iteration of the \textit{Counting} loop and \textit{Sorting} loop.

\[ t_{count} = 3.6355 \times 10^{-9}s,\quad t_{sort} = 2.3273 \times  10^{-8} s \]

Then, because these loops will be executed \( \frac{64}{b}  \) times, we can express the execution time of the algorithm as

\begin{align*}
    T\left( n,b \right) &= \frac{64}{b} \cdot \left( n \cdot t_{count} + n \cdot t_{sort} \right) \\
                        &= \frac{64n}{b} \cdot \left( t_{count} + t_{sort} \right)\\
                        &= \frac{64n}{b} \cdot \left( 3.6355 \times 10^{-9} + 2.3273 \times  10^{-8} \right)\\
                        &= \frac{64n}{b} \cdot 2.69085 \times 10^{-8}s\\
\end{align*}

Now that we have this expression, we can compare it to the actual execution time of the algorithm, and see how well it holds up. 


\pgfplotstableread{
Label Actual Expression
1 32.53 103.32
2 16.45 51.66
4 9.61 25.83
8 14.02 12.92
16 17.97 6.46
}\testdata
\begin{figure}[H]
    \begin{center}
\begin{tikzpicture}
\begin{axis}[
    ybar,
    ymin=0,
    ymax=105,
    ylabel={Time [s]},
    xtick=data,
    xticklabels from table={\testdata}{Label},
    xticklabel style={text width=2cm,align=center},
    xlabel={\( b \)-value},
    legend pos=outer north east,
    legend style={cells={anchor=west},fill=GBBackground,draw=GBForeground, legend pos=outer north east},
    % reverse legend=true, % set to false to get correct display, but I'd like to have this true
    bar width=10pt,
]
% Add the data, ensuring the x values are in the log scale (if necessary)
\addplot [fill=GBGreen] table [y=Actual, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Actual Time}
\addplot [fill=GBRed] table [y=Expression, meta=Label, x expr=\coordindex] {\testdata};
\addlegendentry{Expression Time}
\end{axis}
\end{tikzpicture}
    \end{center}
    \caption{Comparison between execution time according to expression and actual execution time.}
\end{figure}

Unsurprisingly, the expression isn't accurate at all, as the values obtained for \( t_{count} \) and \( t_{sort} \) is different every time the algorithm is ran, and so it is impossible to determine an accurate value for these variables which is general enough to hold for all combinations of \( n \) and \( b \). It should also be noted that the value for these variables were obtained from a program compiled with \texttt{-O3}, which may introduce unforseen optimizations that make the expression dubious at best.


\section*{Problem 3}
\addcontentsline{toc}{section}{Problem 3}

\section*{Problem 4}
\addcontentsline{toc}{section}{Problem 4}

\subsection*{Strong Scaling}
\addcontentsline{toc}{subsection}{Strong Scaling}

\pgfplotstableread{
Label Speedup
1
5
10
20
30
40
50
60
70
80
}\testdata



\end{document}
